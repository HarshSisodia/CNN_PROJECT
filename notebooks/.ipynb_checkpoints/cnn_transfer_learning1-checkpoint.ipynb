{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Transfer Learning with ResNet50\n",
    "\n",
    "This notebook demonstrates how to use transfer learning with ResNet50 for image classification on the CIFAR-10 dataset. The approach leverages pre-trained weights from ImageNet and adds a custom classification head for the specific task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the utils directory to the path\n",
    "sys.path.append('../utils')\n",
    "from data_utils import load_cifar10_data, preprocess_data, create_data_augmentation, visualize_samples\n",
    "from model_utils import create_resnet50_model, create_callbacks, train_model, evaluate_model, plot_training_history, predict_and_visualize, unfreeze_layers\n",
    "from visualization import plot_confusion_matrix, visualize_feature_maps, visualize_model_architecture, visualize_augmented_images, visualize_class_activation_maps\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load and Preprocess Data\n",
    "\n",
    "We'll load the CIFAR-10 dataset and preprocess it for our model. This includes resizing the images to 224x224 (required for ResNet50), normalizing pixel values, and converting labels to one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define class names for CIFAR-10\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "               'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "# Load CIFAR-10 dataset with a smaller subset for faster training\n",
    "# Use (5000, 1000) for a smaller subset or None for the full dataset\n",
    "(x_train, y_train), (x_test, y_test) = load_cifar10_data(subset_size=(5000, 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize some sample images from the dataset\n",
    "visualize_samples(x_train, y_train, class_names, num_samples=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the data (resize to 224x224 for ResNet50, normalize, and convert labels to one-hot)\n",
    "(x_train, y_train), (x_test, y_test) = preprocess_data(\n",
    "    x_train, y_train, x_test, y_test, \n",
    "    resize_dim=(224, 224), \n",
    "    one_hot=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data augmentation pipeline\n",
    "data_augmentation = create_data_augmentation()\n",
    "\n",
    "# Visualize augmented images\n",
    "visualize_augmented_images(data_augmentation, x_train[0:1], num_augmentations=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create and Compile the Model\n",
    "\n",
    "We'll use transfer learning with ResNet50 pre-trained on ImageNet. We'll freeze the base layers and add our own classification head."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "model = create_resnet50_model(\n",
    "    input_shape=(224, 224, 3),\n",
    "    num_classes=10,\n",
    "    freeze_layers=True\n",
    ")\n",
    "\n",
    "# Visualize the model architecture\n",
    "visualize_model_architecture(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train the Model\n",
    "\n",
    "We'll train the model with the frozen base layers first, then optionally fine-tune by unfreezing some layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create callbacks for training\n",
    "callbacks = create_callbacks(\n",
    "    checkpoint_path='../models/saved_models/resnet50_cifar10.h5',\n",
    "    patience=5\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model, history = train_model(\n",
    "    model=model,\n",
    "    x_train=x_train,\n",
    "    y_train=y_train,\n",
    "    batch_size=32,\n",
    "    epochs=15,  # Start with fewer epochs for the initial training\n",
    "    validation_split=0.2,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "# Plot training history\n",
    "plot_training_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Fine-tune the Model (Optional)\n",
    "\n",
    "After initial training with frozen base layers, we can unfreeze some layers and continue training with a lower learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unfreeze the last few layers of the base model for fine-tuning\n",
    "model = unfreeze_layers(model, num_layers_to_unfreeze=10)\n",
    "\n",
    "# Continue training with a lower learning rate\n",
    "model, fine_tune_history = train_model(\n",
    "    model=model,\n",
    "    x_train=x_train,\n",
    "    y_train=y_train,\n",
    "    batch_size=32,\n",
    "    epochs=10,  # Additional epochs for fine-tuning\n",
    "    validation_split=0.2,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "# Plot fine-tuning history\n",
    "plot_training_history(fine_tune_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluate the Model\n",
    "\n",
    "Now we'll evaluate the model on the test set and visualize the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on test data\n",
    "test_loss, test_accuracy = evaluate_model(model, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions and visualize results\n",
    "predict_and_visualize(model, x_test, y_test, class_names, num_samples=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix\n",
    "plot_confusion_matrix(model, x_test, y_test, class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualize Model Interpretability\n",
    "\n",
    "Let's visualize feature maps and class activation maps to understand what the model is looking at."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize feature maps for a sample image\n",
    "sample_image = x_test[0]\n",
    "visualize_feature_maps(model, sample_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize class activation maps\n",
    "# Get the predicted class for the sample image\n",
    "pred = model.predict(np.expand_dims(sample_image, axis=0))\n",
    "pred_class = np.argmax(pred[0])\n",
    "\n",
    "# Visualize class activation map for the predicted class\n",
    "visualize_class_activation_maps(model, sample_image, pred_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Save the Model\n",
    "\n",
    "Finally, let's save the trained model for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model_save_path = '../models/saved_models/resnet50_cifar10_final.h5'\n",
    "model.save(model_save_path)\n",
    "print(f\"Model saved to {model_save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Conclusion\n",
    "\n",
    "In this notebook, we've demonstrated how to use transfer learning with ResNet50 for image classification on the CIFAR-10 dataset. We've shown the complete pipeline from data loading and preprocessing to model training, evaluation, and visualization.\n",
    "\n",
    "Key takeaways:\n",
    "- Transfer learning allows us to leverage pre-trained models for new tasks\n",
    "- Data augmentation helps prevent overfitting and improves generalization\n",
    "- Fine-tuning can further improve performance after initial training\n",
    "- Visualization techniques help understand what the model is learning"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
